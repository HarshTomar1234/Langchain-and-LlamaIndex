{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoJ-RGiUo-uJ"
   },
   "source": [
    "# Langchain: The basics\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/b33t7ivjx6oture/YT-cover-vid%231-edited2.png\" alt=\"LangChain Basics\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18788,
     "status": "ok",
     "timestamp": 1715342333503,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "8RSTxnoIozRN",
    "outputId": "3ab1801e-6492-4ebb-ef02-be9a2e817d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install openai langchain huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1715342470214,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "9iIacDfgpB2M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your key'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'your token'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KB9qA8bpxgJ"
   },
   "source": [
    "## Plain Conditional Generation\n",
    "\n",
    "### First with OpenAI GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1715342546487,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "-lzO5PfUpwfv"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1517,
     "status": "ok",
     "timestamp": 1715342661165,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "sTiEn3tKp7mZ"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct',\n",
    "             temperature=0.9,\n",
    "             max_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4528,
     "status": "ok",
     "timestamp": 1715342810812,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "WCBfxD4cqXsx",
    "outputId": "9894b2b2-d41c-4efb-87a5-68d6fded83be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Virat Kohli is known as the King by his fans and the cricketing world for his exceptional talent, skills, and achievements in the sport of cricket. He has broken numerous records, won several awards and accolades, and established himself as one of the greatest cricketers of all time.\n",
      "\n",
      "1. Consistent Performance: Kohli has consistently performed well in all formats of the game, whether it is Test cricket, One Day Internationals (ODIs), or Twenty20 (T20) matches. He has scored over 11,000 runs in both Test and ODI cricket, becoming the fastest player in the world to achieve this feat.\n",
      "\n",
      "2. Leadership Skills: Kohli is also known for his exceptional leadership skills, having led the Indian cricket team to numerous victories in all three formats of the game. He is known for his aggressive and fearless attitude on the field, which has helped the team achieve success.\n",
      "\n",
      "3. Record-Breaking Performances: Kohli has broken several records in his career, including the record for the fastest century by an Indian player in ODI cricket (52 balls), the fastest player to reach 10,000 runs in ODI cricket, and the most runs scored by an Indian player in a single IPL season (973\n"
     ]
    }
   ],
   "source": [
    "text = \"Why did the Virat Kohli known as King?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCx_zw5dqxH3"
   },
   "source": [
    "### Now with T5-Flan-XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3wBv-L2aQhg"
   },
   "source": [
    "The **T5-Flan-XL** is a fascinating model!\n",
    "\n",
    "The **T5-Flan-XL** is a text-to-image model developed by the Hugging Face team, specifically designed for generating high-quality images from text prompts. It's an extension of the **Flan-T5** model, which is a large-scale language model pre-trained on a massive dataset of text.\n",
    "\n",
    "Here are some key features of the **T5-Flan-XL** model:\n",
    "\n",
    "* **Text-to-Image Generation**: The model can generate images from text prompts, allowing for creative and innovative applications.\n",
    "\n",
    "* **Large-scale Pre-training**: The model is pre-trained on a massive dataset of text, which enables it to learn complex patterns and relationships in language.\n",
    "\n",
    "* **XL-sized**: The model has a large capacity, allowing it to process and generate complex images.\n",
    "\n",
    "\n",
    "Other popular Hugging Face models include:\n",
    "\n",
    "* **Bert**: A pre-trained language model that has achieved state-of-the-art results in a wide range of NLP tasks, from sentiment analysis to question answering.\n",
    "\n",
    "* **RoBERTa**: A variant of BERT that uses a different approach to pre-training, achieving even better results in many NLP tasks.\n",
    "\n",
    "* **DistilBERT**: A smaller, more efficient version of BERT, designed for deployment on edge devices and mobile devices.\n",
    "\n",
    "* **ViLBERT**: A model that combines the strengths of computer vision and natural language processing to perform tasks like image captioning and visual question answering.\n",
    "\n",
    "* **Flan-T5**: The precursor to the T5-Flan-XL model, also designed for text-to-image generation and other NLP tasks.\n",
    "These models have been widely adopted in various industries, from healthcare to finance, and have enabled breakthroughs in areas like chatbots, language translation, and text summarization.\n",
    "\n",
    "Keep in mind that these models are constantly evolving, and new models are being developed to tackle specific challenges and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMsaKN3gbNBN"
   },
   "source": [
    "**LLaMA**: A large-scale language model that achieves state-of-the-art results in various NLP tasks, including language translation, text classification, and question answering.\n",
    "\n",
    "**Bloom**: A large-scale language model that's designed for efficient inference and deployment on edge devices, making it suitable for real-world applications.\n",
    "\n",
    "**DALL-E**: A text-to-image model that generates high-quality images from text prompts, similar to the T5-Flan-XL model I mentioned earlier.\n",
    "\n",
    "**Cohere**: A language model that's specifically designed for conversational AI applications, such as chatbots and virtual assistants.\n",
    "\n",
    "**Pegasus**: A text-to-text model that's designed for generating long-form text, such as articles and stories, from short prompts.\n",
    "\n",
    "**T5-3B**: An updated version of the T5 model, with a larger capacity and improved performance on various NLP tasks.\n",
    "\n",
    "**ViLBERT**: A model that combines the strengths of computer vision and natural language processing to perform tasks like image captioning and visual question answering.\n",
    "\n",
    "**Visual BERT**: A model that uses a combination of computer vision and natural language processing to perform tasks like image captioning and visual question answering.\n",
    "\n",
    "**DALL-E Mini**: A smaller version of the DALL-E model, designed for deployment on edge devices and mobile devices.\n",
    "\n",
    "**LLaMA Mini**: A smaller version of the LLaMA model, designed for deployment on edge devices and mobile devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1715342849927,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "cZYdStv_rSVU"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1715342852556,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "swswqGCyqi7A",
    "outputId": "00d9e2c8-0309-40ad-d1b5-589d4c4c8e48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm_hf = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-small\",\n",
    "    model_kwargs={\"temperature\":0.9 }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1715343364017,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "NUwUR9U7qkld",
    "outputId": "a6c121a4-2b2f-4fd6-b907-aaa723068950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a chicken was a pig\n"
     ]
    }
   ],
   "source": [
    "text = \"Why did the chicken cross the road?\"\n",
    "\n",
    "print(llm_hf(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xidOhWp7rk_5"
   },
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1715343393977,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "dWFJY6-Qrm0L"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "restaurant_template = \"\"\"\n",
    "I want you to act as a naming consultant for new restaurants.\n",
    "\n",
    "Return a list of restaurant names. Each name should be short, catchy and easy to remember. It shoud relate to the type of restaurant you are naming.\n",
    "\n",
    "What are some good names for a restaurant that is {restaurant_desription}?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"restaurant_desription\"],\n",
    "    template=restaurant_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1715344002158,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "iQ0EEAywYkAb"
   },
   "outputs": [],
   "source": [
    "# An example prompt with one input variable\n",
    "prompt_template = PromptTemplate(input_variables=[\"restaurant_desription\"], template=restaurant_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1715344005318,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "qB3E-mPeYkH-",
    "outputId": "28c6e202-6b87-4558-e865-3dd6a9f06011"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nI want you to act as a naming consultant for new restaurants.\\n\\nReturn a list of restaurant names. Each name should be short, catchy and easy to remember. It shoud relate to the type of restaurant you are naming.\\n\\nWhat are some good names for a restaurant that is a Greek place that serves fresh lamb souvlakis and other Greek food ?\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = \"a Greek place that serves fresh lamb souvlakis and other Greek food \"\n",
    "description_02 = \"a burger place that is themed with baseball memorabilia\"\n",
    "description_03 = \"a cafe that has live hard rock music and memorabilia\"\n",
    "\n",
    "## to see what the prompt will be like\n",
    "prompt_template.format(restaurant_desription=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2594,
     "status": "ok",
     "timestamp": 1715344132817,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "KtuuvvmTayhz",
    "outputId": "e309aa49-0ef5-4d2a-a55f-30ee39aa85de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Home Plate Burgers\n",
      "2. Bat and Burger\n",
      "3. Diamond Diner\n",
      "4. Burger Sluggers\n",
      "5. The Grand Slam Grill\n",
      "6. Bleacher Burger Co.\n",
      "7. Ballpark Bites\n",
      "8. Burger Legends\n",
      "9. Swingin' Sides\n",
      "10. Burger Hall of Fame\n",
      "11. The Burger Diamond\n",
      "12. Take Me Out to the Grill\n",
      "13. Burger Batter Up\n",
      "14. The Burger Fieldhouse\n",
      "15. Slugger's Burgers & Fries\n"
     ]
    }
   ],
   "source": [
    "## querying the model with the prompt template\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt_template)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(description_02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aiOsgwJX_Ol"
   },
   "source": [
    "## with Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1715344161705,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "a2AncvoJxON6"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1715344209691,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "2WOFpG-RxOVb"
   },
   "outputs": [],
   "source": [
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1715344221417,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "qkDsAyF3xS7b"
   },
   "outputs": [],
   "source": [
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"\n",
    "Word: {word}\n",
    "Antonym: {antonym}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1715344263380,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "ihj7fUsDxTGb"
   },
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1715344372665,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "eJuHdj9wxNFq",
    "outputId": "7c7d8bcf-d1f7-4c1d-faab-c4a54d1b8123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "\n",
      "Word: big\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can now generate a prompt using the `format` method.\n",
    "print(few_shot_prompt.format(input=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1715345248970,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "pDC56SM8FEzu",
    "outputId": "ac23bc71-ef80-4fe6-9024-fffe57c8d818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " small\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pStpc2HIFY-9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1BkpMLfYEofhNK-PCKCSj9_SJqnUK40gR",
     "timestamp": 1715342272369
    },
    {
     "file_id": "1ACsB89KcXbLSrg7dHZGjXlSbxwZ6VZU5",
     "timestamp": 1676950283172
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
