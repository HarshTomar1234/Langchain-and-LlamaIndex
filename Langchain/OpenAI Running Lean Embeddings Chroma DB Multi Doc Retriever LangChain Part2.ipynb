{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 14218,
     "status": "ok",
     "timestamp": 1718459761932,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "RRYSu48huSUW"
   },
   "outputs": [],
   "source": [
    "!pip -q install langchain openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-93gNGa1MX63"
   },
   "source": [
    "\n",
    "### Unstructured\n",
    "\n",
    "Unstructured is a toolkit designed to connect large language models (LLMs) to various data sources. It provides a set of tools for extracting and transforming complex data from different file formats, such as PDFs, Word documents, and Markdown, into a format that can be used by LLMs. The toolkit includes an open-source library, a paid API, and an upcoming enterprise platform. The main goals of Unstructured are:\n",
    "\n",
    "- **Open Source**: To provide a simple and reliable entry point for individual developers to build prototype applications using LLMs.\n",
    "- **API**: To offer a production-ready API with premium features for development teams, including advanced models for PDF and image processing, improved table and image extraction, and additional chunking and metadata capabilities.\n",
    "- **Enterprise Platform**: To provide a full-featured ETL (Extract, Transform, Load) experience with supported upstream and downstream connectors, job scheduling, and incremental data loads, all aimed at automating the LLM ETL process.\n",
    "\n",
    "### Pandoc\n",
    "\n",
    "Pandoc is a Haskell library and command-line tool for converting files between different markup formats. It can convert between numerous formats, including Markdown, HTML, LaTeX, and Word docx, and can also produce PDF output. Pandoc has a modular design, consisting of readers that parse input formats and writers that convert the parsed data into target formats. This architecture allows it to perform a wide range of conversions.\n",
    "\n",
    "Pandoc is often used for tasks such as:\n",
    "\n",
    "- **Format Conversion**: Converting documents between different formats, such as Markdown to HTML or LaTeX to PDF.\n",
    "- **Document Processing**: Extracting structural elements from documents, such as headers, paragraphs, and tables.\n",
    "- **Customization**: Allowing users to run custom filters to modify the intermediate abstract syntax tree (AST) during the conversion process.\n",
    "\n",
    "In summary, Unstructured is focused on preparing data for use with large language models, while Pandoc is a more general-purpose tool for converting and processing documents between different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 11297,
     "status": "ok",
     "timestamp": 1718459773215,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "VvxK_GGgy5jg"
   },
   "outputs": [],
   "source": [
    "!pip -q install unstructured pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11080,
     "status": "ok",
     "timestamp": 1718459784262,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "J-KFB7J_u_3L",
    "outputId": "0111c31e-5bae-4124-be69-abf2b9638d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.2.5\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: aiohttp, async-timeout, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6XPLPVrqEaV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace ash_videos/ash_maurya/k0MsYFp-YvY.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!wget -q https://www.dropbox.com/s/zdwh3dy5jc7xq94/ash_maurya.zip\n",
    "!unzip -q ash_maurya.zip -d ash_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd-2zd6Zuci5"
   },
   "outputs": [],
   "source": [
    "!ls ash_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# LangChain multi-doc retriever with ChromaDB\n",
    "\n",
    "***New Points***\n",
    "- Multiple Files - Text + Epub\n",
    "- ChromaDB -\n",
    "- gpt-3.5-turbo API\n",
    "- OpenAI Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## Setting up LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmeazXicXmZ-"
   },
   "outputs": [],
   "source": [
    "! pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## Load multiple and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('./ash_videos/ash_maurya/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vT6KgAIT_BtB"
   },
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiqIxHjZzZbe"
   },
   "source": [
    "## Load Epub\n",
    "\n",
    "Comment this out if you don't have an Epub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "872ECJLENFlJ"
   },
   "source": [
    "# EPUB\n",
    "\n",
    "**EPUB (short for Electronic Publication) is a widely used file format for digital books and publications. It is designed to be flexible and adaptable, allowing the content to be easily read and displayed on various devices, including e-readers, smartphones, and tablets.**\n",
    "\n",
    "### Key Features of EPUB Files\n",
    "\n",
    "1. **Reflowable Content**: EPUB files can adjust their layout to fit different screen sizes, making them ideal for reading on devices with varying screen dimensions.\n",
    "2. **XML-Based**: EPUB files are built using XML, which ensures that the content is structured and easily parseable.\n",
    "3. **Support for Multimedia**: EPUB files can include multimedia elements such as images, audio, and video, enhancing the reading experience.\n",
    "4. **Metadata and Annotations**: EPUB files can contain metadata, such as author and title information, and support for annotations, making them useful for educational and research purposes.\n",
    "5. **Open Standard**: EPUB is an open standard, maintained by the International Digital Publishing Forum (IDPF), ensuring that it is widely supported and compatible with various devices and software.\n",
    "\n",
    "### Creating and Opening EPUB Files\n",
    "\n",
    "1. **Creation**: EPUB files can be created using software such as Adobe InDesign, which allows users to design and export their content in the EPUB format.\n",
    "2. **Opening**: EPUB files can be opened and read using various e-readers and software, including Adobe Digital Editions, Apple's iBooks, and many other e-reader applications.\n",
    "\n",
    "### Advantages and Uses\n",
    "\n",
    "1. **Portability**: EPUB files are highly portable and can be easily transferred between devices, making them ideal for reading on the go.\n",
    "2. **Accessibility**: EPUB files can be optimized for accessibility, including support for screen readers and other assistive technologies.\n",
    "3. **Flexibility**: EPUB files can be used for a wide range of content, from novels and textbooks to comics and technical publications.\n",
    "\n",
    "### Tools and Resources\n",
    "\n",
    "1. **EPUBCheck**: A free online tool for validating EPUB files, ensuring they conform to the EPUB standard.\n",
    "2. **Adobe Digital Editions**: A popular software for reading and managing EPUB files, available for both Windows and Mac.\n",
    "3. **EPUBBooks**: A website offering a large collection of free EPUB and Kindle eBooks for download.\n",
    "\n",
    "Overall, EPUB is a versatile and widely supported format that has become a standard in the digital publishing industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYzLy9ofWeu1"
   },
   "outputs": [],
   "source": [
    "!pip install pandoc==2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uuzytpz7zbbv"
   },
   "outputs": [],
   "source": [
    "!pip install pypandoc\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredEPubLoader\n",
    "\n",
    "loader = UnstructuredEPubLoader(\"/content/Running Lean_ Iterate from Plan A to a Plan That Works (Lean Series) - Maurya, Ash.epub\")  #, mode=\"elements\")\n",
    "\n",
    "epub_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66ZifUv-0Z9F"
   },
   "outputs": [],
   "source": [
    "len(epub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts_01 = text_splitter.split_documents(documents)\n",
    "texts_02 = text_splitter.split_documents(epub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlU5AlqY4gwj"
   },
   "outputs": [],
   "source": [
    "len(texts_01), len(texts_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auoq_XM14Iov"
   },
   "outputs": [],
   "source": [
    "texts = texts_01 + texts_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faD-Ab-Y4W1X"
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bg6-9jwU4ja_"
   },
   "outputs": [],
   "source": [
    "texts[370]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhs0C0FYASlM"
   },
   "source": [
    "## OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Emj46ATxtV9C"
   },
   "outputs": [],
   "source": [
    "# Download embeddings from OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## create the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_eTIZwf4Dk2"
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## Here is the nmew embeddings being used\n",
    "embedding = embeddings\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siLXR-XT0JoI"
   },
   "source": [
    "## Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ObunFU30Lxh"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYA-H59u0Skn"
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is product market fit?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0iAuh_B0ZjE"
   },
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vws1udbPaPmQ"
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVWgPJXs1yRq"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4N0IhRM0hHL"
   },
   "outputs": [],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jXL9u-u0prF"
   },
   "outputs": [],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ia-4OXa5IeP"
   },
   "source": [
    "## Make a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGx8XblM4shW"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp2e3Sh25zY2"
   },
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygJC5Xqw6liS"
   },
   "outputs": [],
   "source": [
    "qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template = '''\n",
    "Your name is Ash Maurya. You are an expert at Lean Startups.\n",
    "Use the following pieces of context to answer the users question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Always answer from the perspective of being Ash Maurya.\n",
    "----------------\n",
    "{context}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZEo26mw8e5k"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKfX4vX-5RFT"
   },
   "outputs": [],
   "source": [
    "# full example\n",
    "query = \"What is product market fit?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olRm73t3rNt2"
   },
   "outputs": [],
   "source": [
    "# break it down\n",
    "query = \"When should you quit or pivot?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "# llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg-e6fh6rNwz"
   },
   "outputs": [],
   "source": [
    "query = \"What is the purpose of a customer interview?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkksVXfs7If7"
   },
   "outputs": [],
   "source": [
    "query = \"What is your name?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuFf8D-rrN0I"
   },
   "outputs": [],
   "source": [
    "query = \"What are the customer interviewing techniques?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMyu13ouwgqs"
   },
   "outputs": [],
   "source": [
    "query = \"Do you like the color blue?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "692pHNkFrN5z"
   },
   "outputs": [],
   "source": [
    "query = \"What books did you write?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "978QWCeJSRdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "name": "",
   "provenance": [
    {
     "file_id": "15l5LlHgJvUHyH-ghD8XiFTva8X1EmbT9",
     "timestamp": 1718377917115
    },
    {
     "file_id": "1x4zRNxi_x7TcCyz2czwVBNlbjMGuC45s",
     "timestamp": 1685715806219
    },
    {
     "file_id": "1SXLsEhOKMk9162Qn_GgWdRJq-AFbz8C1",
     "timestamp": 1685703325444
    },
    {
     "file_id": "17eByD88swEphf-1fvNOjf_C79k0h2DgF",
     "timestamp": 1685685911881
    },
    {
     "file_id": "1_Ei_y2qPct07dKQHKNHkXl8LHLehfd8w",
     "timestamp": 1683715732115
    },
    {
     "file_id": "1BO8UHPNzQR7t_8AnOY9S3yr6Xk4XUHyb",
     "timestamp": 1683705272518
    },
    {
     "file_id": "1gBBk8ATdmsq6jV2ayd4SFxaTDTu81Qb3",
     "timestamp": 1683626576221
    },
    {
     "file_id": "1gWrd0P4f4DloYX0_ds4NiRUiXGO8rI7l",
     "timestamp": 1683592210355
    },
    {
     "file_id": "1DvVjynVZYvhJQp4yZbLXLByhqRdu6GkB",
     "timestamp": 1683544314022
    },
    {
     "file_id": "1BT_kRFMP27lmwAoWeIhiie0VPs0oqShz",
     "timestamp": 1683524040132
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
