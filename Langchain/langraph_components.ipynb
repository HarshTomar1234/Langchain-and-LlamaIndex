{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c1b5pzLDURa",
        "outputId": "31a4df40-b966-431f-ae7a-957e7291a21f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.40)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain_openai, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.18 langchain_openai-0.3.7 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2db2kUDdt3",
        "outputId": "49be6119-bae2-4362-cc2e-67ea1128a8a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.40)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_prebuilt-0.1.1-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.2 langgraph-checkpoint-2.0.16 langgraph-prebuilt-0.1.1 langgraph-sdk-0.1.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0sjJl1dVC5IJ"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SlvFrmmnDFdQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = TavilySearchResults(max_results=4) #increased number of results\n",
        "print(type(tool))\n",
        "print(tool.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlg_PcuLNdLh",
        "outputId": "5c53f689-736b-4221-c463-bc42c1f3a3d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
            "tavily_search_results_json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]"
      ],
      "metadata": {
        "id": "uTcBeuVvNfub"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Note: in **take_action** below, some logic was added to cover the case that the LLM returned a non-existent tool name. Even with function calling, LLMs can still occasionally hallucinate. Note that all that is done is instructing the LLM to try again! An advantage of an agentic organization."
      ],
      "metadata": {
        "id": "l4t80CuTNf5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, model, tools, system=\"\"):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "        graph.add_node(\"llm\", self.call_openai)\n",
        "        graph.add_node(\"action\", self.take_action)\n",
        "        graph.add_conditional_edges(\n",
        "            \"llm\",\n",
        "            self.exists_action,\n",
        "            {True: \"action\", False: END}\n",
        "        )\n",
        "        graph.add_edge(\"action\", \"llm\")\n",
        "        graph.set_entry_point(\"llm\")\n",
        "        self.graph = graph.compile()\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    def call_openai(self, state: AgentState):\n",
        "        messages = state['messages']\n",
        "        if self.system:\n",
        "            messages = [SystemMessage(content=self.system)] + messages\n",
        "        message = self.model.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def take_action(self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
        "                print(\"\\n ....bad tool name....\")\n",
        "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
        "            else:\n",
        "                result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}"
      ],
      "metadata": {
        "id": "l5kPO4Z7Nf8j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "abot = Agent(model, [tool], system=prompt)"
      ],
      "metadata": {
        "id": "rFNh1juPNf_7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWmeyZk5OU87",
        "outputId": "af7018f6-57bd-4e7c-a3fa-36c5c0843d02"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgvc6-plugins-gtk\n",
            "  librsvg2-common libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "0 upgraded, 9 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 2,434 kB of archives.\n",
            "After this operation, 7,681 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libxdot4 amd64 2.42.2-6ubuntu0.1 [16.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6ubuntu0.1 [22.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgraphviz-dev amd64 2.42.2-6ubuntu0.1 [58.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 2,434 kB in 1s (1,785 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libxdot4:amd64.\n",
            "Preparing to unpack .../4-libxdot4_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgraphviz-dev:amd64.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../8-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Collecting pygraphviz\n",
            "  Using cached pygraphviz-1.14.tar.gz (106 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp311-cp311-linux_x86_64.whl size=169680 sha256=f599be088cc1b6bd4caf4beed489838f7dea7cdf7dfa4926aeee5de18c8675ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/5f/df/6fffd2a4353f26dbb0e3672a1baf070c124a1d74a5f9318279\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import pygraphviz\n",
        "\n",
        "Image(abot.graph.get_graph().draw_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "1I-R7EpnOKJI",
        "outputId": "90dd4dfd-ec9f-41c0-ad91-bd9d7e48cc66"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Which different file system DeepSeek company used to faster inferencing of AI models explain in detailed way?\")]\n",
        "result = abot.graph.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7RxDQkqO1u9",
        "outputId": "6228afbe-63fc-4b56-df1b-755a4413df25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'DeepSeek AI models file system for faster inferencing'}, 'id': 'call_4rcXV3GYhZlLTZfvV6HmewW6', 'type': 'tool_call'}\n",
            "Back to the model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaa1WKqkPSaF",
        "outputId": "0bf8e149-9751-4189-d267-a42d4e9efd72"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Which different file system DeepSeek company used to faster inferencing of AI models explain in detailed way?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4rcXV3GYhZlLTZfvV6HmewW6', 'function': {'arguments': '{\"query\":\"DeepSeek AI models file system for faster inferencing\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 164, 'total_tokens': 192, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d91621c2-3aeb-47b4-a461-8429452507c2-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'DeepSeek AI models file system for faster inferencing'}, 'id': 'call_4rcXV3GYhZlLTZfvV6HmewW6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 164, 'output_tokens': 28, 'total_tokens': 192, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='[{\\'url\\': \\'https://www.threads.net/@theturingpost/post/DGoKEKKub2t/deepseek-shared-their-new-development-fire-flyer-file-system-3fs-a-super-fast-st\\', \\'content\\': \"DeepSeek shared their new development - Fire-Flyer File System (3FS), a super-fast storage system for handling the heavy demands of AI training and inference. DeepSeek shared their new development - Fire-Flyer File System (3FS), a super-fast storage system for handling the heavy demands of AI training and inference.It ensures fast, flexible data access, scalability, and fault tolerance using thousands of SSDs and RDMA networks.3FS can: - Organize large AI datasets - Quickly save AI training progress - Optimize AI inference - Improve dataloading, so AI models can access what they need instantly.Here\\'s how it works: How data is stored and accessed in 3SF?Files are broken into chunks and stored across multiple SSDs for load balancing.• 3FS uses CRAQ replication:- Writes go to the first node and then propagate down the chain.\"}, {\\'url\\': \\'https://jurnals.net/deepseek-unveils-3fs-file-system-revolutionizing-ai-data-management/\\', \\'content\\': \"DeepSeek\\'s 3FS, an open-source distributed file system, promises to boost AI training and inference with its blazing-fast read throughput of 6.6 TiB/s. Addressing this critical need, DeepSeek, a prominent AI technology company, has recently unveiled 3FS (Fire-Flyer File System), an open-source distributed file system designed specifically to optimize AI workflows. High Read Throughput: Boasting a read throughput of 6.6 TiB/s on a 180-node cluster, 3FS enables rapid data access, accelerating AI training and inference processes. DeepSeek\\'s 3FS file system is a significant development in the field of AI data management. A1: The key advantages of 3FS include its significantly higher read throughput, its distributed architecture which allows for scalability and parallel access, and its optimization specifically for AI training and inference processes.\"}, {\\'url\\': \\'https://blog.aitoolhouse.com/deepseek-ai-unveils-fire-flyer-file-system-3fs-a-high-performance-distributed-file-system-for-ai-workloads/\\', \\'content\\': \\'To address these challenges, DeepSeek AI has introduced Fire-Flyer File System (3FS)—a high-performance, distributed file system optimized for AI workflows. For AI inference, 3FS introduces KVCache, a high-speed caching layer that enhances real-time data access. With its high-throughput storage architecture, 3FS minimizes data transfer delays, reducing training times for large-scale AI models. By optimizing data retrieval with KVCache, 3FS improves response times in real-time AI applications, making it ideal for natural language processing, computer vision, and multimodal AI systems. DeepSeek AI’s Fire-Flyer File System (3FS) is a high-performance, AI-optimized distributed file system that addresses the storage challenges of modern AI applications. By leveraging disaggregated storage, strong consistency models, and high-speed caching mechanisms, 3FS significantly improves AI training and inference efficiency.\\'}, {\\'url\\': \\'https://www.marktechpost.com/2025/02/28/deepseek-ai-releases-fire-flyer-file-system-3fs-a-high-performance-distributed-file-system-designed-to-address-the-challenges-of-ai-training-and-inference-workload/\\', \\'content\\': \\'DeepSeek AI Releases Fire-Flyer File System (3FS): A High-Performance Distributed File System Designed to Address the Challenges of AI Training and Inference Workload - MarkTechPost DeepSeek AI Releases Fire-Flyer File System (3FS): A High-Performance Distributed File System Designed to Address the Challenges of AI Training and Inference Workload AI training and inference workloads demand not only significant compute power but also a storage solution that can manage large-scale, concurrent data access. This feature is particularly valuable in AI applications where repeated access to previously computed data, such as key and value vectors in language models, is essential to maintain performance. Functional cookies help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features.\\'}]', name='tavily_search_results_json', tool_call_id='call_4rcXV3GYhZlLTZfvV6HmewW6'),\n",
              "  AIMessage(content='DeepSeek has developed the Fire-Flyer File System (3FS), which is a high-performance, distributed file system optimized for AI workloads. This system is specifically designed to enhance the efficiency and speed of AI model training and inference. Here’s a detailed explanation of how 3FS functions and its key features:\\n\\n1. **High Read Throughput**: 3FS is noted for its impressive read throughput of 6.6 TiB/s on a 180-node cluster. This facilitates rapid data access, thereby accelerating AI training and inference processes.\\n\\n2. **Distributed Architecture**: Being an open-source distributed file system, 3FS allows for scalability and parallel access to data, making it well-suited for large dataset handling.\\n\\n3. **KVCache**: For AI inference, 3FS introduces KVCache, a high-speed caching layer that enhances real-time data access. This mechanism optimizes data retrieval, reducing response times in real-time AI applications.\\n\\n4. **Data and Load Balancing**: Files are broken into chunks and stored across multiple SSDs. This feature ensures load balancing and efficient data distribution across the file system.\\n\\n5. **CRAQ Replication**: Writes are initially sent to the first node and then propagate down the chain. This method provides strong consistency models to ensure data integrity and reliability.\\n\\n6. **Minimized Data Transfer Delays**: The system’s high-throughput storage architecture minimizes data transfer delays, thus reducing training times for large-scale AI models.\\n\\n7. **Optimized for AI Workflows**: 3FS is specifically designed to improve data management in AI applications like natural language processing, computer vision, and multimodal AI systems.\\n\\nThe Fire-Flyer File System (3FS) represents a significant advancement in the field of AI data management, addressing the challenges of managing large-scale, concurrent data access necessary for effective AI training and inference.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 383, 'prompt_tokens': 1085, 'total_tokens': 1468, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-32c00315-39f2-43b8-af05-88e8d5fc16e8-0', usage_metadata={'input_tokens': 1085, 'output_tokens': 383, 'total_tokens': 1468, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "-UKIUP50PVKR",
        "outputId": "01d49a5d-b055-4589-f314-822e81c3680f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DeepSeek has developed the Fire-Flyer File System (3FS), which is a high-performance, distributed file system optimized for AI workloads. This system is specifically designed to enhance the efficiency and speed of AI model training and inference. Here’s a detailed explanation of how 3FS functions and its key features:\\n\\n1. **High Read Throughput**: 3FS is noted for its impressive read throughput of 6.6 TiB/s on a 180-node cluster. This facilitates rapid data access, thereby accelerating AI training and inference processes.\\n\\n2. **Distributed Architecture**: Being an open-source distributed file system, 3FS allows for scalability and parallel access to data, making it well-suited for large dataset handling.\\n\\n3. **KVCache**: For AI inference, 3FS introduces KVCache, a high-speed caching layer that enhances real-time data access. This mechanism optimizes data retrieval, reducing response times in real-time AI applications.\\n\\n4. **Data and Load Balancing**: Files are broken into chunks and stored across multiple SSDs. This feature ensures load balancing and efficient data distribution across the file system.\\n\\n5. **CRAQ Replication**: Writes are initially sent to the first node and then propagate down the chain. This method provides strong consistency models to ensure data integrity and reliability.\\n\\n6. **Minimized Data Transfer Delays**: The system’s high-throughput storage architecture minimizes data transfer delays, thus reducing training times for large-scale AI models.\\n\\n7. **Optimized for AI Workflows**: 3FS is specifically designed to improve data management in AI applications like natural language processing, computer vision, and multimodal AI systems.\\n\\nThe Fire-Flyer File System (3FS) represents a significant advancement in the field of AI data management, addressing the challenges of managing large-scale, concurrent data access necessary for effective AI training and inference.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"How smolagents agent building framework in different from langraph and which one is best utilized in different scenarios?\")]\n",
        "result = abot.graph.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cnjQoyEPz-z",
        "outputId": "71c3cffe-2890-42a1-992c-13577a04becb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'smolagents agent building framework overview'}, 'id': 'call_lPkrWu73CaScwUUZhrbJpQKh', 'type': 'tool_call'}\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'langraph agent building framework overview'}, 'id': 'call_kIdBS15ge3kDaIbXS0Tu4a9l', 'type': 'tool_call'}\n",
            "Back to the model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['messages'][-1].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "kTofuIHzQM8e",
        "outputId": "987985ac-16d2-4184-97da-c984f10ebfa7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here\\'s an overview of the two frameworks, SmolAgents and LangGraph, including their distinctive features and best-use scenarios:\\n\\n### SmolAgents\\n1. **Design Philosophy**: SmolAgents, developed by Hugging Face, offers a minimalist and lightweight architecture designed for building powerful AI-driven agents with ease. It\\'s known for requiring minimal code to deploy robust agents.\\n   \\n2. **Focus on Code Agents**: SmolAgents specializes in \"code agents,\" which write and execute Python code snippets to perform actions. This approach is contrasted with generating actions as JSON or text blobs.\\n\\n3. **Tool-Calling Agents**: Besides code agents, SmolAgents also supports traditional tool-calling agents, writing actions as JSON or text blocks; this flexibility allows it to suit specific scenarios and requirements.\\n\\n4. **Use Cases**: SmolAgents is well-suited for scenarios where simplicity and lightweight setup are essential, and when rapid deployment of agents with minimal infrastructure is required.\\n\\n### LangGraph\\n1. **Complexity and Flexibility**: LangGraph handles more complex workflows with graph-based orchestration, persistent state management, and multi-agent coordination, making it perfect for advanced applications requiring sophistication and control.\\n\\n2. **Stateful Graphs and Memory Management**: It provides fine-grained control over both the flow and state of agent applications. It facilitates dynamic decision-making, cyclical graphs for iterative processes, and built-in memory management.\\n\\n3. **Integration with LangChain**: It works with LangChain and LangSmith for enhanced monitoring and optimization, and can create complex agent workflows using stateful graphs.\\n\\n4. **Use Cases**: LangGraph is ideal for developers aiming to build complex, stateful, and controlled agentic applications or workflows, making it suitable for dynamic and iterative AI processes requiring persistent state and memory.\\n\\n### Conclusion\\n\\n- **SmolAgents** is best utilized when you need to deploy straightforward, lightweight agents quickly and efficiently without requiring extensive setup or control over agent states.\\n  \\n- **LangGraph** is more appropriate for applications demanding complex workflows, state management, and coordination among multiple agents, especially where monitoring and iterative processes are integral to the application\\'s functioning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the new quantum chip released by microsoft company explain its features, advantages and also how quantum computers plays crucial role in AI future advancements?\"\n",
        "messages = [HumanMessage(content=query)]\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "abot = Agent(model, [tool], system=prompt)\n",
        "result = abot.graph.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CSm4KIVQV9U",
        "outputId": "cc3f8158-22b8-4cd7-96da-69243a92ddde"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Microsoft new quantum chip features advantages 2023'}, 'id': 'call_PoQgGCk7YpdHMIYpv6i79c1t', 'type': 'tool_call'}\n",
            "Back to the model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2EtOgAlRLXD",
        "outputId": "09efa2e1-68b8-4a40-a4d2-fac809bb1e64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft recently unveiled a quantum chip named \"Majorana 1,\" which is designed to pave the way for future advancements in quantum computing. Here are some of its features and the implications for the future, especially in artificial intelligence (AI):\n",
            "\n",
            "### Features of the Majorana 1 Chip:\n",
            "1. **Topological Core Architecture:** Majorana 1 is powered by a new Topological Core architecture that offers a path to develop quantum systems capable of scaling up to a million qubits. This architecture uses a stack of indium arsenide and aluminum materials, manipulating magnetic fields to create Majorana particles.\n",
            "   \n",
            "2. **Scalability:** The chip currently hosts eight qubits but is part of Microsoft’s ambition to build scalable quantum computers that can eventually solve complex industrial and societal problems in much shorter timescales.\n",
            "\n",
            "3. **Stability and Reliability:** The chip aims to provide more stable quantum computing environments via topological qubits, which bring about more robust error correction mechanisms.\n",
            "\n",
            "4. **Partnerships and Research:** Microsoft collaborates with companies like Quantinuum and Atom Computing to achieve scientific breakthroughs and push the boundaries of what can be done with quantum computing today.\n",
            "\n",
            "### Advantages of Quantum Chips like Majorana 1:\n",
            "- **Industrial Problem Solving:** Quantum chips have the potential to solve complex problems that are currently beyond the reach of classical computers, similar to how semiconductors revolutionized computing in the past.\n",
            "  \n",
            "- **Faster Computation:** They can potentially perform calculations and run simulations at unprecedented speeds, leading to breakthroughs in various fields such as materials science, cryptography, and complex system modeling.\n",
            "\n",
            "### Quantum Computers' Role in AI:\n",
            "Quantum computers have the potential to significantly advance AI in several ways:\n",
            "\n",
            "1. **Enhanced Machine Learning:** Quantum computing can process and analyze large datasets much faster than classical computers, making machine learning models more efficient and faster to train.\n",
            "\n",
            "2. **Complex Optimization Problems:** AI often involves complex optimization problems (e.g., selecting the best model parameters), which quantum algorithms can solve more efficiently.\n",
            "\n",
            "3. **New AI Algorithms:** The unique properties of quantum mechanics can potentially lead to the development of new AI algorithms that are more powerful and efficient than current methods.\n",
            "\n",
            "4. **Simulation of Quantum Worlds:** AI can be used in conjunction with quantum computing to simulate quantum systems, leading to better understanding and new discoveries in quantum physics and beyond.\n",
            "\n",
            "Overall, Microsoft's Majorana 1 chip is a step toward a future where quantum computers could substantially enhance technological and computational capabilities, significantly impacting AI development and its applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wdcmXQpkSbCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ows0ZKPLSbHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od48eicMSbKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XEk9SPrBSbPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langraph"
      ],
      "metadata": {
        "id": "N5Bp2qMfSbRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### What is LangGraph?\n",
        "\n",
        "LangGraph is an orchestration framework within the LangChain ecosystem designed for building complex, stateful, and multi-agent AI applications. Unlike simple linear chains, LangGraph lets you design workflows as directed graphs that may include cycles (loops) and branching logic. This structure helps manage the interactions between different agents (or nodes) and external tools.\n",
        "\n",
        "---\n",
        "\n",
        "### Core Components\n",
        "\n",
        "#### 1. **Nodes**\n",
        "\n",
        "- **Definition:** Nodes are the individual units of work in a LangGraph. Each node is typically a Python function that processes input, calls a language model (LLM), or executes a tool.\n",
        "- **Example Use:** A node might be a chatbot function that takes conversation history as input and generates a response using an LLM.\n",
        "- **Key Point:** Nodes can be combined and reused, making it easy to design complex workflows.\n",
        "\n",
        "#### 2. **Edges**\n",
        "\n",
        "- **Definition:** Edges connect nodes and define the flow of information through the graph.\n",
        "- **Types:**\n",
        "  - **Direct Edges:** These simply link one node to another.\n",
        "  - **Conditional Edges:** These include logic (like if-else statements) to decide which node to execute next based on the state.\n",
        "- **Key Point:** Edges determine the overall structure of the application, whether it's linear, cyclic, or branching.\n",
        "\n",
        "#### 3. **State**\n",
        "\n",
        "- **Definition:** The state is a shared data object that is passed between nodes. It typically includes the conversation history (messages) and can also store other data (like user information or facts extracted from the conversation).\n",
        "- **How It Works:** When a node returns an update (e.g., a new message), the state is updated—usually by appending new information to the existing state.\n",
        "- **Key Point:** State management is automatic and can be persisted (checkpointed) so that the graph can resume execution or “remember” past interactions.\n",
        "\n",
        "---\n",
        "\n",
        "### How LangGraph Works\n",
        "\n",
        "1. **Designing the Graph:**\n",
        "   - You start by defining the state (usually as a dictionary or a Pydantic model).\n",
        "   - Next, you add nodes (functions) that represent distinct tasks (e.g., calling an LLM, executing a search tool, etc.).\n",
        "   - Then, you connect these nodes with edges to create the desired workflow.\n",
        "   \n",
        "2. **Tool Integration:**\n",
        "   - Tools are external services or functions (like web search, database access, or human input) that your agent can call.\n",
        "   - LangGraph allows you to bind tools to an LLM, so the model learns which JSON format to use when invoking a tool.\n",
        "   \n",
        "3. **Memory & Checkpointing:**\n",
        "   - To enable multi-turn conversations, LangGraph can persist state through a checkpointing system.\n",
        "   - This means your chatbot can “remember” previous interactions, making it capable of context-aware responses.\n",
        "   - Advanced users can also integrate long-term memory solutions (like Zep) for storing and retrieving facts over many sessions.\n",
        "\n",
        "4. **Human-in-the-loop:**\n",
        "   - For tasks requiring oversight or correction, you can interrupt the graph execution (using functions like `interrupt`) to get human feedback.\n",
        "   - The human input is then used to update the state, ensuring higher reliability.\n",
        "\n",
        "5. **Time Travel:**\n",
        "   - LangGraph’s checkpointing system even allows you to “rewind” to previous states. This is useful for debugging, error recovery, or exploring alternative conversation paths.\n",
        "\n",
        "---\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- **Chatbots & Virtual Assistants:** Manage complex multi-turn conversations with memory and human oversight.\n",
        "- **Autonomous Agents:** Build agents that can autonomously choose which tool to call based on the task.\n",
        "- **Workflow Automation:** Design systems where multiple agents collaborate to execute complex business processes.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Use LangGraph?\n",
        "\n",
        "- **Flexibility:** Its graph-based design supports complex workflows (including loops and conditional logic) which are hard to implement with simple chains.\n",
        "- **Built-in Persistence:** Automatic state checkpointing allows for context retention across sessions.\n",
        "- **Tool Integration:** Easily extend functionality by incorporating external tools and APIs.\n",
        "- **Human Oversight:** Supports human-in-the-loop workflows, increasing reliability and control over autonomous decisions.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wq6oZN4LTC8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Understanding LangGraph\n",
        "\n",
        "LangGraph is a library built on top of LangChain that helps developers create complex, stateful workflows for language model applications. It's essentially a framework for building stateful multi-agent systems using language models.\n",
        "\n",
        "## Core Concepts of LangGraph\n",
        "\n",
        "### State Machines and Graphs\n",
        "\n",
        "At its heart, LangGraph uses the concept of a directed graph (or state machine) to organize the flow of information in an application. This approach allows you to:\n",
        "\n",
        "1. Define distinct \"states\" your application can be in\n",
        "2. Create explicit transitions between these states\n",
        "3. Maintain memory and context throughout the execution flow\n",
        "\n",
        "This structure is particularly valuable when you need your application to make decisions about what to do next based on previous steps and current conditions.\n",
        "\n",
        "### Components of LangGraph\n",
        "\n",
        "#### 1. Nodes\n",
        "\n",
        "Nodes represent distinct processing steps in your application. Each node is a function that:\n",
        "- Takes the current state as input\n",
        "- Performs some computation (often involving an LLM)\n",
        "- Returns an updated state\n",
        "\n",
        "For example, a node might:\n",
        "- Parse user input\n",
        "- Generate a response with an LLM\n",
        "- Execute a tool or API call\n",
        "- Make a decision about the next step\n",
        "\n",
        "#### 2. Edges\n",
        "\n",
        "Edges define the possible transitions between nodes. They determine which node should execute next based on the current state.\n",
        "\n",
        "#### 3. State\n",
        "\n",
        "The state is a shared memory object that persists throughout the execution of your graph. It allows information to be passed between nodes and maintains the context of the conversation or task.\n",
        "\n",
        "## Why LangGraph is Useful for Beginners\n",
        "\n",
        "### 1. Structured Approach to Complex Applications\n",
        "\n",
        "For beginners, one of the challenges of building LLM applications is managing the complexity of multi-step processes. LangGraph provides a clear structure for breaking down complex tasks into manageable pieces.\n",
        "\n",
        "### 2. Visualization and Debugging\n",
        "\n",
        "LangGraph allows you to visualize your application flow, making it easier to understand how different components interact. This visualization is invaluable for debugging and explaining your application to others.\n",
        "\n",
        "### 3. Reusable Components\n",
        "\n",
        "The modular nature of LangGraph allows beginners to start with simple components and gradually build up complexity. You can reuse components across different applications.\n",
        "\n",
        "## Creating a Simple LangGraph Application\n",
        "\n",
        "Let me show you how to create a basic LangGraph application. I'll walk through the process step by step:\n",
        "\n",
        "```python\n",
        "# Install necessary packages\n",
        "!pip install langchain langchain-core langchain-community langgraph\n",
        "\n",
        "# Import required libraries\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph\n",
        "import operator\n",
        "from typing import TypedDict, List, Literal\n",
        "\n",
        "# Define the state structure\n",
        "class AgentState(TypedDict):\n",
        "    messages: List\n",
        "    next_step: Literal[\"generate\", \"decide\", \"end\"]\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Define node functions\n",
        "def generate(state):\n",
        "    # Prompt for generating a response\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ])\n",
        "    \n",
        "    # Chain the prompt with the LLM\n",
        "    chain = prompt | llm\n",
        "    \n",
        "    # Generate response\n",
        "    response = chain.invoke({\"messages\": state[\"messages\"]})\n",
        "    \n",
        "    # Update state with the new message\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [AIMessage(content=response.content)],\n",
        "        \"next_step\": \"decide\"\n",
        "    }\n",
        "\n",
        "def decide(state):\n",
        "    # Decide if we need more information or can end the conversation\n",
        "    last_message = state[\"messages\"][-1].content\n",
        "    \n",
        "    if \"need more information\" in last_message.lower():\n",
        "        return {\"next_step\": \"generate\"}\n",
        "    else:\n",
        "        return {\"next_step\": \"end\"}\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"decide\", decide)\n",
        "\n",
        "# Define edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"decide\",\n",
        "    lambda state: state[\"next_step\"],\n",
        "    {\n",
        "        \"generate\": \"generate\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Test the application\n",
        "result = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What is LangGraph?\")],\n",
        "    \"next_step\": \"generate\"\n",
        "})\n",
        "\n",
        "# Print the conversation\n",
        "for message in result[\"messages\"]:\n",
        "    print(f\"{message.type}: {message.content}\\n\")\n",
        "```\n",
        "\n",
        "## Advanced LangGraph Features\n",
        "\n",
        "### 1. Multi-Agent Systems\n",
        "\n",
        "LangGraph excels at creating systems where multiple agents with different roles collaborate:\n",
        "\n",
        "```python\n",
        "# Define agent roles\n",
        "def researcher(state):\n",
        "    # Research relevant information\n",
        "    # ...\n",
        "\n",
        "def planner(state):\n",
        "    # Create a plan based on research\n",
        "    # ...\n",
        "\n",
        "def executor(state):\n",
        "    # Execute the plan\n",
        "    # ...\n",
        "\n",
        "# Connect them in a workflow\n",
        "workflow.add_node(\"researcher\", researcher)\n",
        "workflow.add_node(\"planner\", planner)\n",
        "workflow.add_node(\"executor\", executor)\n",
        "```\n",
        "\n",
        "### 2. Tool Use and External Integrations\n",
        "\n",
        "LangGraph can integrate with external tools and APIs:\n",
        "\n",
        "```python\n",
        "def use_calculator(state):\n",
        "    # Extract math expression from state\n",
        "    expression = extract_math_expression(state[\"messages\"])\n",
        "    \n",
        "    # Calculate result\n",
        "    result = eval(expression)\n",
        "    \n",
        "    # Update state with result\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [AIMessage(content=f\"The result is {result}\")],\n",
        "        \"next_step\": \"decide\"\n",
        "    }\n",
        "\n",
        "# Add tool to graph\n",
        "workflow.add_node(\"calculator\", use_calculator)\n",
        "```\n",
        "\n",
        "### 3. Human-in-the-Loop Processes\n",
        "\n",
        "LangGraph supports workflows where humans provide input at critical decision points:\n",
        "\n",
        "```python\n",
        "def get_human_feedback(state):\n",
        "    # Display current state to human\n",
        "    print(\"Current plan:\", state[\"plan\"])\n",
        "    \n",
        "    # Get feedback\n",
        "    feedback = input(\"Your feedback: \")\n",
        "    \n",
        "    # Update state with feedback\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [HumanMessage(content=feedback)],\n",
        "        \"next_step\": \"revise\"\n",
        "    }\n",
        "```\n",
        "\n",
        "## Real-World Applications of LangGraph\n",
        "\n",
        "1. **Conversational Agents**: Build chatbots that maintain context over long conversations and can switch between different conversation modes.\n",
        "\n",
        "2. **Research Assistants**: Create agents that can break down research tasks, search for information, synthesize findings, and present results.\n",
        "\n",
        "3. **Workflow Automation**: Automate complex business processes that require decision-making and adaptation.\n",
        "\n",
        "4. **Content Creation**: Build systems that plan, draft, edit, and refine content based on specific guidelines.\n"
      ],
      "metadata": {
        "id": "KfJo3aosSdYT"
      }
    }
  ]
}