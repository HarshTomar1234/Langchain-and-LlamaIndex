{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epcuhls9LaAV"
   },
   "source": [
    "# Knowledge Graph\n",
    "\n",
    "**A knowledge graph is a type of database that stores information in the form of entities and their relationships.** It's a powerful tool for organizing and querying complex data, and it's widely used in artificial intelligence, natural language processing, and other fields.\n",
    "\n",
    "Here's a breakdown of what a knowledge graph is:\n",
    "\n",
    "**Entities**: In a knowledge graph, entities are the objects, concepts, or things that we want to store information about. These can be anything from people, places, and organizations to abstract concepts like events, ideas, or relationships.\n",
    "\n",
    "**Relationships**: Relationships are the connections between entities. These can be simple relationships like \"Person A is friends with Person B\" or more complex relationships like \"Company X is a subsidiary of Company Y.\"\n",
    "\n",
    "**Graph Structure**: A knowledge graph is typically represented as a graph, with entities as nodes and relationships as edges between those nodes. This structure allows for efficient querying and traversal of the graph.\n",
    "\n",
    "**Properties and Attributes**: Entities and relationships in a knowledge graph can have properties and attributes that provide additional information. For example, a person entity might have properties like \"name,\" \"age,\" and \" occupation,\" while a relationship like \"friendship\" might have attributes like \"start date\" and \"end date.\"\n",
    "\n",
    "**Types of Knowledge Graphs**: There are several types of knowledge graphs, including:\n",
    "\n",
    "* **Domain-specific knowledge graphs**: These focus on a specific domain or industry, like a knowledge graph of medical concepts or a knowledge graph of financial entities.\n",
    "* **General knowledge graphs**: These cover a broad range of topics and are often used as a general-purpose knowledge base.\n",
    "* **Hybrid knowledge graphs**: These combine different types of knowledge graphs, like a knowledge graph that combines medical and financial information.\n",
    "\n",
    "**Applications of Knowledge Graphs**: Knowledge graphs have many applications, including:\n",
    "\n",
    "* **Question answering**: Knowledge graphs can be used to answer complex questions by traversing the graph and retrieving relevant information.\n",
    "* **Recommendation systems**: Knowledge graphs can be used to build recommendation systems that take into account complex relationships between entities.\n",
    "* **Natural language processing**: Knowledge graphs can be used to improve natural language processing tasks like entity recognition, sentiment analysis, and text summarization.\n",
    "* **Data integration**: Knowledge graphs can be used to integrate data from multiple sources, providing a unified view of the data.\n",
    "\n",
    "Some popular examples of knowledge graphs include:\n",
    "\n",
    "* **Google's Knowledge Graph**: A massive knowledge graph that provides information about entities like people, places, and things.\n",
    "* **Wikidata**: A knowledge graph that provides information about entities like people, places, and things, with a focus on verifiability and transparency.\n",
    "* **DBpedia**: A knowledge graph that extracts information from Wikipedia and makes it available for querying and analysis.\n",
    "\n",
    "I hope this helps Let me know if you have any further questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjCyKxvMLs3o"
   },
   "source": [
    "# ChromaDB\n",
    "\n",
    "**ChromaDB is a database system designed specifically for Langchain, a conversational AI framework. It's a crucial component that enables Langchain agents to store and retrieve knowledge graphs, which are essential for generating accurate and informative responses.**\n",
    "\n",
    "Here's a breakdown of what ChromaDB does:\n",
    "\n",
    "**Knowledge Graph Storage**: ChromaDB is designed to store knowledge graphs, which are complex networks of entities, relationships, and concepts. These graphs are used by Langchain agents to reason about the world, answer questions, and generate responses.\n",
    "\n",
    "**Database System**: ChromaDB is a database system that provides a structured way of storing and retrieving knowledge graphs. It's optimized for fast querying and retrieval of graph data, making it an ideal choice for Langchain agents.\n",
    "\n",
    "**Features**: ChromaDB provides several features that make it well-suited for Langchain agents, including:\n",
    "\n",
    "* **Graph storage**: ChromaDB can store large knowledge graphs with millions of nodes and edges.\n",
    "* **Querying**: ChromaDB provides a powerful querying system that allows Langchain agents to retrieve specific nodes, edges, or subgraphs from the knowledge graph.\n",
    "* **Indexing**: ChromaDB uses indexing to speed up querying and retrieval of graph data.\n",
    "* **Scalability**: ChromaDB is designed to scale horizontally, making it suitable for large-scale Langchain deployments.\n",
    "\n",
    "**Benefits**: By using ChromaDB, Langchain agents can:\n",
    "\n",
    "* **Improve response accuracy**: By storing and retrieving knowledge graphs, Langchain agents can generate more accurate and informative responses.\n",
    "* **Increase knowledge coverage**: ChromaDB enables Langchain agents to store and retrieve large knowledge graphs, increasing their knowledge coverage and ability to answer complex questions.\n",
    "* **Enhance conversational capabilities**: By leveraging ChromaDB, Langchain agents can engage in more sophisticated conversations, using their knowledge graphs to reason about the world and respond to user queries.\n",
    "\n",
    "Overall, ChromaDB is a critical component of the Langchain ecosystem, enabling agents to store and retrieve knowledge graphs and generate accurate and informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10941,
     "status": "ok",
     "timestamp": 1718241751486,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "RRYSu48huSUW"
   },
   "outputs": [],
   "source": [
    "!pip -q install langchain openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8408,
     "status": "ok",
     "timestamp": 1718241759889,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "J-KFB7J_u_3L",
    "outputId": "83b77aba-4b8e-4f47-eaaa-3cbc91005e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.2.3\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: aiohttp, async-timeout, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156643,
     "status": "ok",
     "timestamp": 1718241916524,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "l6XPLPVrqEaV",
    "outputId": "c4c318b5-0db5-4ad2-f4db-e17a0bad8217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace new_articles/05-07-fintech-space-continues-to-be-competitive-and-drama-filled.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-07-spacex-starship-startups-future.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-04-microsoft-doubles-down-on-ai-with-new-bing-features.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-ai-replace-tv-writers-strike.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-05-vint-cerf-on-the-exhilarating-mix-of-thrill-and-hazard-at-the-frontiers-of-tech.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-06-ai-startups-q1-investments.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-05-google-i-o-2023-is-next-week-heres-what-were-expecting.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-05-with-deepfloyd-generative-ai-art-gets-a-text-upgrade.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-05-google-and-openai-are-walmarts-besieged-by-fruit-stands.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-04-cma-generative-ai-review.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "replace new_articles/05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
    "!unzip -q new_articles.zip -d new_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# LangChain multi-doc retriever with ChromaDB\n",
    "\n",
    "***New Points***\n",
    "- Multiple Files\n",
    "- ChromaDB\n",
    "- Source info\n",
    "- gpt-3.5-turbo API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## Setting up LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718241916524,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10452,
     "status": "ok",
     "timestamp": 1718241926971,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "QQPLCDrIMtbP",
    "outputId": "1bbcd2b4-a1b8-4f35-9962-7f6fdb489f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1718241927730,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## Load multiple and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1718241928522,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718241928522,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718241928522,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "TlU5AlqY4gwj",
    "outputId": "78ac1282-de28-4696-f324-a34050a990bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718241928523,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "Bg6-9jwU4ja_",
    "outputId": "c2e4f1d7-232f-4d94-c338-2877aa57f6f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='BrandGPT is designed for working with third parties like an agency or a contractor, who can ask questions about the company’s brand guidelines to make sure they are complying with them, May said. “We’re launching BrandGPT, which is meant to be the interface to all this brand-related security stuff that we’re doing, and as people interact with brands, they can access the style guides and better understand the brand, whether they’re a part of the company or not.\\n\\nThese two products are available in public beta starting today. The company launched last year and has raised $2.4 million from Bee Partners, Fyrfly Ventures and Argon Ventures.', metadata={'source': 'new_articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## create the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6013,
     "status": "ok",
     "timestamp": 1718241934532,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "Q_eTIZwf4Dk2",
    "outputId": "84deea3f-5a82-4dc9-9f5b-dbf880557067"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1718241934532,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "uRfD_Te-47lb",
    "outputId": "a15e629c-9c23-4fb5-c543-02cc45931757"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718241934532,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "A-h1y_eAHmD-"
   },
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siLXR-XT0JoI"
   },
   "source": [
    "## Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718241934533,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "6ObunFU30Lxh"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1718241935403,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "cYA-H59u0Skn",
    "outputId": "25d0a08a-c8b4-42d5-db48-469c9cb5fd03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"How much money did Pando raise?\")\n",
    "# docs = retriever.invoke(\"How much money did Pando raise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1718241935403,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "h0iAuh_B0ZjE",
    "outputId": "11dc9a8a-bd7f-42a3-decb-a21a85c51a33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1718241935404,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "jVWgPJXs1yRq"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1718241935404,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "H4N0IhRM0hHL",
    "outputId": "ac591a9a-cfb3-4eda-a369-d910b85b6817"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1718241935404,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "4jXL9u-u0prF",
    "outputId": "a17664ac-ba37-4840-f386-78c942558d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ia-4OXa5IeP"
   },
   "source": [
    "## Make a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrEqcM8iOmcA"
   },
   "source": [
    "LangChain provides several search types for its retriever interface, which are used to select relevant text chunks from a vector database. Here are some examples:\n",
    "\n",
    "1. **Similarity Search**:\n",
    "   - This type of search selects text chunk vectors that are most similar to the query. It is useful when you want to retrieve the most relevant documents based on their semantic similarity to the query.\n",
    "\n",
    "2. **Maximum Marginal Relevance (MMR) Search**:\n",
    "   - This type of search optimizes for both similarity to the query and diversity among the retrieved documents. It ensures that the retrieved documents are not only relevant but also diverse in their content.\n",
    "\n",
    "These search types are used in conjunction with various components of LangChain, such as the `RetrievalQA` and `ConversationalRetrievalChain`, to create powerful question answering systems that can retrieve relevant information from a database and generate contextually aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGx8XblM4shW"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718241935405,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "LZEo26mw8e5k"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1718241936204,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "wKfX4vX-5RFT",
    "outputId": "9f5782c5-bd73-41e7-ec6a-f99803b9c2b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pando has raised a total of $45 million, with $30 million coming from their most recent Series B round.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1718241936997,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "olRm73t3rNt2",
    "outputId": "e4b71d79-d6f8-4c70-8dc5-d4b8144651be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the news about Pando?',\n",
       " 'result': ' Pando announced that it raised $30 million in a Series B round, bringing its total raised to $45 million. The funding will be used to expand its global sales, marketing, and delivery capabilities, and Pando is open to exploring strategic partnerships and acquisitions.',\n",
       " 'source_documents': [Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
       "  Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"What is the news about Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "# process_llm_response(llm_response)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1569,
     "status": "ok",
     "timestamp": 1718241938564,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "wg-e6fh6rNwz",
    "outputId": "604dfdf0-ac0f-48ac-ca47-b5abb888f12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iron Pillar and Uncorrelated Ventures.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Who led the round in Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1718241939482,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "cuFf8D-rrN0I",
    "outputId": "049b0c32-b1f9-460b-8737-01dc1210bb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Databricks acquired Okera, a data governance solution company.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles/05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What did databricks acquire?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1718241940487,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "t5KETxphrN3d",
    "outputId": "51910e2f-0f2a-427a-bd17-ae3cfca4d18f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generative AI is a type of artificial intelligence that allows users to create new content or experiences through the use of external apps and large language models. It can be incorporated into the Slack platform in customized ways, giving users more choice and flexibility in how they bring AI into their work. \n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
      "new_articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What is generative ai?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1718241941252,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "692pHNkFrN5z",
    "outputId": "ec735d75-9c45-42e7-a361-acadf43898e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CMA stands for Competition and Markets Authority.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-04-cma-generative-ai-review.txt\n",
      "new_articles/05-04-cma-generative-ai-review.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is CMA?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718241941253,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "IPIhZWAR5n3X",
    "outputId": "ff28bb41-34c2-498c-acf9-441163918a0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('similarity',\n",
       " <langchain_community.vectorstores.chroma.Chroma at 0x791ffe367e50>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1718241941253,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "3_lp0_796P_-",
    "outputId": "c465cbf8-00fd-4dae-ac4c-0e8f3da2e096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSxVCnNi5h1-"
   },
   "source": [
    "## Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1718241942020,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "H7xmepGJ2GAE",
    "outputId": "68a73742-ccea-4acd-f48b-785be08773e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: db/ (stored 0%)\n",
      "updating: db/chroma.sqlite3 (deflated 39%)\n",
      "updating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/ (stored 0%)\n",
      "updating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/data_level0.bin (deflated 100%)\n",
      "updating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/header.bin (deflated 61%)\n",
      "updating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/length.bin (deflated 99%)\n",
      "updating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/link_lists.bin (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1718241942641,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "Jl84qGQt5Wu5"
   },
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2r0ZIBPJp-K"
   },
   "source": [
    "## Starting again loading the db\n",
    "\n",
    "restart the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20967,
     "status": "ok",
     "timestamp": 1718242538656,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "8pc7CM_mTQAt",
    "outputId": "e45ac880-10ef-46e8-f94e-d9917aa66fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\n",
      "replace db/chroma.sqlite3? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: db/chroma.sqlite3       \n",
      "replace db/35238da2-46ed-43d3-872f-4ab389f3c4f4/data_level0.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/data_level0.bin  \n",
      "replace db/35238da2-46ed-43d3-872f-4ab389f3c4f4/header.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/header.bin  \n",
      "replace db/35238da2-46ed-43d3-872f-4ab389f3c4f4/length.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/length.bin  \n",
      "replace db/35238da2-46ed-43d3-872f-4ab389f3c4f4/link_lists.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      " extracting: db/35238da2-46ed-43d3-872f-4ab389f3c4f4/link_lists.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1718242545388,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "us3F8ZKeRiz2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1718242550616,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "qK1nY4PkKYGo"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2100,
     "status": "ok",
     "timestamp": 1718242592023,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "396RyNbS4EXx",
    "outputId": "9fce3163-3d3d-4ca4-ae31-90eb187bad1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1718242599895,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "F3vkSxxYKCZ9",
    "outputId": "561b63c0-4d44-49d6-8f3d-696d65dab447"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1718242606656,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "PsR60NH5KCfj"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm,\n",
    "                                  chain_type=\"stuff\",\n",
    "                                  retriever=retriever,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1718242610623,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "RWulTG0eKCfk"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2830,
     "status": "ok",
     "timestamp": 1718242616590,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "mDp-g2FtKCfk",
    "outputId": "59a11793-b878-494b-d01b-bd339a335fea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pando raised $30 million in its Series B round, bringing its total raised amount to $45 million.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fPl26c-TbWw"
   },
   "source": [
    "### Chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1718242622906,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "wwyuhrpu5XqM",
    "outputId": "cabaecd0-3014-49df-98df-9aa44f1ca326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1718242629362,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "LcWXvSCHRvHO",
    "outputId": "d981c830-d679-45c3-c7ad-a2b77705b813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1718241943380,
     "user": {
      "displayName": "Harsh Tomar",
      "userId": "07306423374395310283"
     },
     "user_tz": -330
    },
    "id": "978QWCeJSRdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1gyGZn_LZNrYXYXa-pltFExbptIe7DAPe",
     "timestamp": 1717435954046
    },
    {
     "file_id": "1gWrd0P4f4DloYX0_ds4NiRUiXGO8rI7l",
     "timestamp": 1683551886622
    },
    {
     "file_id": "1DvVjynVZYvhJQp4yZbLXLByhqRdu6GkB",
     "timestamp": 1683544314022
    },
    {
     "file_id": "1BT_kRFMP27lmwAoWeIhiie0VPs0oqShz",
     "timestamp": 1683524040132
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
